{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793da7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(x, mean, std):\n",
    "    return np.exp(-0.5*np.square((x-mean)/std))\n",
    "\n",
    "def ExcesiveDark(x, M):\n",
    "    return G(x, -25, M/9)\n",
    "\n",
    "def VeryDark(x, M):\n",
    "    return G(x, 0, M/9)\n",
    "\n",
    "def Dark(x, M):\n",
    "    return G(x, M/2, M/9)\n",
    "\n",
    "def ModeratelyDark(x, M):\n",
    "    return G(x, 5*M/4, M/9)\n",
    "\n",
    "def ModeratelyBright(x, M):\n",
    "    return G(x, M+(255-M)/9, (255-M)/9)\n",
    "\n",
    "def Bright(x, M):\n",
    "    return G(x, M+(255-M)/2, (255-M)/9)\n",
    "\n",
    "def VeryBright(x, M):\n",
    "    return G(x, 255, (255-M)/9)\n",
    "\n",
    "def ExtremelyBright(x, M):\n",
    "    return G(x, 300, (255-M)/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59aa15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for M in (128, 64, 192):\n",
    "    x = np.arange(-50, 306)\n",
    "    \n",
    "    ED = ExtremelyDark(x, M)\n",
    "    VD = VeryDark(x, M)\n",
    "    Da = Dark(x, M)\n",
    "    SD = MediumDark(x, M)\n",
    "    SB = MediumBright(x, M)\n",
    "    Br = Bright(x, M)\n",
    "    VB = VeryBright(x, M)\n",
    "    EB = ExtremelyBright(x, M)\n",
    "    \n",
    "def OutputFuzzySet(x, f, M, thres):\n",
    "    x = np.array(x)\n",
    "    result = f(x, M)\n",
    "    result[result > thres] = thres\n",
    "    return result\n",
    "\n",
    "def AggregateFuzzySets(fuzzy_sets):\n",
    "    return np.max(np.stack(fuzzy_sets), axis=0)\n",
    "\n",
    "def Infer(i, M, get_fuzzy_set=False):\n",
    "    # Calculate degree of membership for each class\n",
    "    VD = VeryDark(i, M)\n",
    "    Da = Dark(i, M)\n",
    "    SD = MediumDark(i, M)\n",
    "    SB = MediumBright(i, M)\n",
    "    Br = Bright(i, M)\n",
    "    VB = VeryBright(i, M)\n",
    "    \n",
    "    \n",
    "    x = np.arange(-50, 306)\n",
    "    Inferences = (\n",
    "        OutputFuzzySet(x, ExtremelyDark, M, VD),\n",
    "        OutputFuzzySet(x, VeryDark, M, Da),\n",
    "        OutputFuzzySet(x, Dark, M, SD),\n",
    "        OutputFuzzySet(x, Bright, M, SB),\n",
    "        OutputFuzzySet(x, VeryBright, M, Br),\n",
    "        OutputFuzzySet(x, ExtremelyBright, M, VB)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fuzzy_output = AggregateFuzzySets(Inferences)\n",
    "    \n",
    "    \n",
    "    if get_fuzzy_set:\n",
    "        return np.average(x, weights=fuzzy_output), fuzzy_output\n",
    "    return np.average(x, weights=fuzzy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FuzzyContrastEnhance(rgb):\n",
    "    \n",
    "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    l = lab[:, :, 0]\n",
    "       \n",
    "    M = np.mean(l)\n",
    "    if M < 128:\n",
    "        M = 127 - (127 - M)/2\n",
    "    else:\n",
    "        M = 128 + M/2\n",
    "           \n",
    "    x = list(range(-50,306))\n",
    "    FuzzyTransform = dict(zip(x,[Infer(np.array([i]), M) for i in x]))\n",
    "    \n",
    "    \n",
    "    u, inv = np.unique(l, return_inverse = True)\n",
    "    l = np.array([FuzzyTransform[i] for i in u])[inv].reshape(l.shape)\n",
    "        \n",
    "    Min = np.min(l)\n",
    "    Max = np.max(l)\n",
    "    lab[:, :, 0] = (l - Min)/(Max - Min) * 255\n",
    "        \n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def HE(rgb):\n",
    "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    lab[:, :, 0] = cv2.equalizeHist(lab[:, :, 0])\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "def CLAHE(rgb):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    lab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
    "    lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b325d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalAvgPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAvgPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        x = F.avg_pool2d(x, (H, W))\n",
    "        x = x.view(N, C)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Darknet19(BaseModel):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(Darknet19, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "        ('layer1', nn.Sequential(OrderedDict([\n",
    "            ('conv1_1', nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn1_1', nn.BatchNorm2d(32)),\n",
    "            ('leaky1_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer2', nn.Sequential(OrderedDict([\n",
    "            ('conv2_1', nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2_1', nn.BatchNorm2d(64)),\n",
    "            ('leaky2_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer3', nn.Sequential(OrderedDict([\n",
    "            ('conv3_1', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_1', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_2', nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn3_2', nn.BatchNorm2d(64)),\n",
    "            ('leaky3_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv3_3', nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn3_3', nn.BatchNorm2d(128)),\n",
    "            ('leaky3_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool3', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer4', nn.Sequential(OrderedDict([\n",
    "            ('conv4_1', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_1', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_2', nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn4_2', nn.BatchNorm2d(128)),\n",
    "            ('leaky4_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv4_3', nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn4_3', nn.BatchNorm2d(256)),\n",
    "            ('leaky4_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool4', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer5', nn.Sequential(OrderedDict([\n",
    "            ('conv5_1', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_1', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_2', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn5_2', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_3', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_3', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_4', nn.Conv2d(512, 256, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_4', nn.BatchNorm2d(256)),\n",
    "            ('leaky5_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv5_5', nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn5_5', nn.BatchNorm2d(512)),\n",
    "            ('leaky5_5', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('maxpool5', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        ]))),\n",
    "        ('layer6', nn.Sequential(OrderedDict([\n",
    "            ('conv6_1', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_1', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_1', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_2', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=0, bias=False)),\n",
    "            ('bn6_2', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_2', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_3', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_3', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_3', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_4', nn.Conv2d(1024, 512, kernel_size=1, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_4', nn.BatchNorm2d(512)),\n",
    "            ('leaky6_4', nn.LeakyReLU(0.1, inplace=True)),\n",
    "            ('conv6_5', nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn6_5', nn.BatchNorm2d(1024)),\n",
    "            ('leaky6_5', nn.LeakyReLU(0.1, inplace=True))\n",
    "        ])))\n",
    "        ]))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "        ('conv7_1', nn.Conv2d(1024, 1000, kernel_size=(1, 1), stride=(1, 1))),\n",
    "        ('globalavgpool', GlobalAvgPool2d()),\n",
    "        ('softmax', nn.Softmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "        if pretrained:\n",
    "            self.load_state_dict(model_zoo.load_url(model_paths['darknet19'],  progress=True))\n",
    "            print('Model is loaded')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "base_model = Darknet19(weights='imagenet', input_shape=(224,224,3))\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "dark_train_features = model_feat.predict(x_train)\n",
    "dark_test_features=model_feat.predict(x_test)\n",
    "\n",
    "    \n",
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=(224,224,3),\n",
    "    pooling=None\n",
    ")\n",
    "\n",
    "X_feat_out = base_model.output\n",
    "X_feat_flatten = Flatten()(X_feat_out)\n",
    "\n",
    "X_feat_model = Model(inputs = base_model.input,outputs = X_feat_flatten)\n",
    "incep_train_features = X_feat_model.predict(X_train)\n",
    "incep_test_features = X_feat_model.predict(X_test)\n",
    "\n",
    "base_model = ResNet101(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "x = base_model.output\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "res_train_features = model_feat.predict(x_train)\n",
    "res_test_features=model_feat.predict(x_test)\n",
    "\n",
    "X_train = Concatenate([res_train_features, incep_train_features, dark_train_features])\n",
    "X_test = Concatenate([res_test_features, incep_test_features, dark_test_features])\n",
    "import sklearn_relief as sr\n",
    "r = sr.RReliefF(n_features = 146)\n",
    "print(r.fit_transform(X_train,y_train))\n",
    "\n",
    "knn.fit(X_train, y_train) \n",
    "print(knn.predict(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b513454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_test,y_test):\n",
    "    kidney_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred_train= kidney_fit.predict(X_train)\n",
    "    y_pred_test = kidney_fit.predict(X_test)\n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
    "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),4) \n",
    "    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "    print(\"accuracy : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall : {}\".format(test_recall))\n",
    "    print(\"Precision : {}\".format(test_precision))\n",
    "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
